{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLeFxUoGSmdS"
   },
   "source": [
    "# Resume Classifier Project\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO9jf5qxSvth"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g1TdEi5pSV_S"
   },
   "outputs": [],
   "source": [
    "# !pip install PyPDF2\n",
    "# !pip install gradio-pdf\n",
    "# !pip install fitz\n",
    "# !pip install pymupdf\n",
    "# !pip install nltk\n",
    "import tensorflow as tf, keras, numpy as np, pandas as pd\n",
    "# import kagglehub\n",
    "import nltk, os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "import PyPDF2\n",
    "from gradio_pdf import PDF\n",
    "import re\n",
    "import joblib\n",
    "import os\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uq8L2H7USy4E"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "n5IO4qc-AZEy"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# files.upload()\n",
    "\n",
    "# !ls /content/drive/MyDrive/ResumeClassifier\n",
    "\n",
    "# drive_path = '/content/drive/MyDrive/ResumeClassifier/resume-dataset'\n",
    "# path = kagglehub.dataset_download(\"gauravduttakiit/resume-dataset\", path=drive_path)\n",
    "# !kaggle datasets download -d gauravduttakiit/resume-dataset\n",
    "# !unzip dataset-name.zip -d /content/drive/MyDrive/ResumeClassifier\n",
    "\n",
    "# file_path = '/content/drive/MyDrive/ResumeClassifier/UpdatedResumeDataSet.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJNjbKRQ-NMb",
    "outputId": "39de9b28-8a15-4667-c749-8aee9284a494"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Science', 'HR', 'Advocate', 'Arts', 'Web Designing',\n",
       "       'Mechanical Engineer', 'Sales', 'Health and fitness',\n",
       "       'Civil Engineer', 'Java Developer', 'Business Analyst',\n",
       "       'SAP Developer', 'Automation Testing', 'Electrical Engineering',\n",
       "       'Operations Manager', 'Python Developer', 'DevOps Engineer',\n",
       "       'Network Security Engineer', 'PMO', 'Database', 'Hadoop',\n",
       "       'ETL Developer', 'DotNet Developer', 'Blockchain', 'Testing'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'https://raw.githubusercontent.com/BrandonYChan/Resume-Screener/refs/heads/main/UpdatedResumeDataSet.csv'\n",
    "resume_df = pd.read_csv(file_path)\n",
    "resume_df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "gEkkztWGKzbW",
    "outputId": "0049bf31-3986-4183-b2bf-e37146620cd4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Computer Skills: â¢ Proficient in MS office (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Testing</td>\n",
       "      <td>â Willingness to accept the challenges. â ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Testing</td>\n",
       "      <td>PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Testing</td>\n",
       "      <td>COMPUTER SKILLS &amp; SOFTWARE KNOWLEDGE MS-Power ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Skill Set OS Windows XP/7/8/8.1/10 Database MY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume\n",
       "0    Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1    Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2    Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3    Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4    Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
       "..            ...                                                ...\n",
       "957       Testing  Computer Skills: â¢ Proficient in MS office (...\n",
       "958       Testing  â Willingness to accept the challenges. â ...\n",
       "959       Testing  PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...\n",
       "960       Testing  COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power ...\n",
       "961       Testing  Skill Set OS Windows XP/7/8/8.1/10 Database MY...\n",
       "\n",
       "[962 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "4Q8opgS3NTUd",
    "outputId": "eb70539b-38f0-4854-bc8c-b0df156d60cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bchan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>skills programming languages python pandas num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>education details may may uitrgpv data scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>areas interest deep learning control system de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>skills r python sap hana tableau sap hana sql ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>education details mca ymcaust faridabad haryan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Testing</td>\n",
       "      <td>computer skills proficient ms office word basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Testing</td>\n",
       "      <td>willingness accept challenges positive thinkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Testing</td>\n",
       "      <td>personal skills quick learner eagerness learn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Testing</td>\n",
       "      <td>computer skills software knowledge mspower poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Testing</td>\n",
       "      <td>skill set os windows xp database mysql sql ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume\n",
       "0    Data Science  skills programming languages python pandas num...\n",
       "1    Data Science  education details may may uitrgpv data scienti...\n",
       "2    Data Science  areas interest deep learning control system de...\n",
       "3    Data Science  skills r python sap hana tableau sap hana sql ...\n",
       "4    Data Science  education details mca ymcaust faridabad haryan...\n",
       "..            ...                                                ...\n",
       "957       Testing  computer skills proficient ms office word basi...\n",
       "958       Testing  willingness accept challenges positive thinkin...\n",
       "959       Testing  personal skills quick learner eagerness learn ...\n",
       "960       Testing  computer skills software knowledge mspower poi...\n",
       "961       Testing  skill set os windows xp database mysql sql ser...\n",
       "\n",
       "[962 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean text\n",
    "resume_df['Resume'] = resume_df['Resume'].str.lower()\n",
    "resume_df['Resume'] = resume_df['Resume'].str.replace(r'[^a-zA-z\\s]', '', regex=True)\n",
    "resume_df['Resume'] = resume_df['Resume'].str.strip().replace(r'\\s', ' ', regex=True)\n",
    "\n",
    "# Remove stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "resume_df['Resume'] = resume_df['Resume'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "resume_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vSqq0Qkd4uc"
   },
   "source": [
    "##Model (initial idea)\n",
    "####Step 1\n",
    "feed cleaned input resume into a model (such as a neural network) trained on the dataset above, which classifies resumes into a category (e.g., Data Science).\n",
    "####Step 2\n",
    "If input resume matches the user-specified category, compare the resume to the job description by searching for key words/skills. If the similarity (e.g., cosine similarity) between the resume and job description is above a certain threshold, assign the resume as 'passable'. In all other cases, assign the resume as 'not passable'.\n",
    "####Extra\n",
    "Maybe we can allow the user to feed in a batch of submitted resumes for a job description, where the code would return a small subset of resumes accepted for interviews. These accepted resumes must have a matching category (assigned by the NN model) to the job description, and must also be the top-performers in terms of cosine similarity to the job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "v__3p2QBeBn4"
   },
   "outputs": [],
   "source": [
    "# Additional imports\n",
    "\n",
    "# !pip install PyPDF2\n",
    "# !pip install gradio-pdf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "import PyPDF2\n",
    "from gradio_pdf import PDF\n",
    "import re\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dt4niMhE9hL2",
    "outputId": "ecab9382-b93d-4ddc-ce26-8752c28b7537"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode labels\n",
    "resume_df_encoded = resume_df.copy()\n",
    "label_encoder = LabelEncoder()\n",
    "resume_df_encoded['Category'] = label_encoder.fit_transform(resume_df_encoded['Category'])\n",
    "Y = to_categorical(resume_df_encoded['Category'])\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CNwFFJV-6mP",
    "outputId": "a2b39ad9-48d5-44f1-bb3d-d47b19094af2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features from text in Resume column\n",
    "tfidf = TfidfVectorizer(max_features=5000) # limit number of features to the top 5000 words with the highest TF-IDF scores across the dataset\n",
    "X = tfidf.fit_transform(resume_df_encoded['Resume']).toarray() # assign weights to words based on their frequency in a resume and rarity across all resumes\n",
    "X # each row represents a resume, and each column represets a word's TF-IDF score; there are 5000 columns, each representing one of the top 5000 most important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhUxtIrP_T0N",
    "outputId": "d3e75a74-febd-4f81-c58d-e0df0d0d85a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673, 5000), (673, 25), (144, 5000), (144, 25), (145, 5000), (145, 25))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into 70% training, 15% val, 15% test\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.3, random_state=13)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, test_size=0.5, random_state=13)\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xfzx5RfpBC4r",
    "outputId": "6354edb3-d5f5-4d75-ce49-f6f901097b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.0918 - loss: 3.1344 - val_accuracy: 0.4097 - val_loss: 2.2468\n",
      "Epoch 2/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6151 - loss: 1.7173 - val_accuracy: 0.9861 - val_loss: 0.2846\n",
      "Epoch 3/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9591 - loss: 0.3035 - val_accuracy: 0.9931 - val_loss: 0.0456\n",
      "Epoch 4/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9948 - loss: 0.0720 - val_accuracy: 0.9931 - val_loss: 0.0285\n",
      "Epoch 5/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0304 - val_accuracy: 0.9931 - val_loss: 0.0190\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0568  \n",
      "Test Accuracy: 0.9862068891525269, Test Loss: 0.08078958094120026\n"
     ]
    }
   ],
   "source": [
    "model_path = '/model.pkl'\n",
    "\n",
    "# Train model if it hasn't already been trained and saved\n",
    "if not(os.path.exists(model_path)):\n",
    "  # Feed data into NN\n",
    "  model = Sequential([\n",
    "      Input(shape=(X.shape[1],)),\n",
    "      Dense(512, activation='relu'),\n",
    "      Dropout(0.3),\n",
    "      Dense(256, activation='relu'),\n",
    "      Dropout(0.3),\n",
    "      Dense(128, activation='relu'),\n",
    "      Dropout(0.3),\n",
    "      Dense(Y.shape[1], activation='softmax')\n",
    "  ])\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=5, batch_size=16, verbose=True)\n",
    "  joblib.dump(model, 'model.pkl')\n",
    "else:\n",
    "  model = joblib.load('model.pkl')\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}, Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ph2D2wKTXgIp",
    "outputId": "196bf41d-d99f-4819-9140-767d0356c3d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Random Resume 1:\n",
      "--Predicted = Python Developer\n",
      "--True = Python Developer\n",
      "Random Resume 2:\n",
      "--Predicted = ETL Developer\n",
      "--True = ETL Developer\n",
      "Random Resume 3:\n",
      "--Predicted = Mechanical Engineer\n",
      "--True = Mechanical Engineer\n",
      "Random Resume 4:\n",
      "--Predicted = Blockchain\n",
      "--True = Blockchain\n",
      "Random Resume 5:\n",
      "--Predicted = Data Science\n",
      "--True = Data Science\n"
     ]
    }
   ],
   "source": [
    "# Show prediction results of some random samples\n",
    "random_indices = np.random.choice(X.shape[0], size=5, replace=False) # SRSWOR of 5 random row indices\n",
    "sample_X = X[random_indices]\n",
    "sample_Y = Y[random_indices]\n",
    "predictions = model.predict(sample_X)\n",
    "predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "true_labels = label_encoder.inverse_transform(np.argmax(sample_Y, axis=1))\n",
    "for i in range(5):\n",
    "    print(f\"Random Resume {i+1}:\\n--Predicted = {predicted_labels[i]}\\n--True = {true_labels[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGHwTUb4DbQ6"
   },
   "source": [
    "## Testing Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "K4Pe4nQ8d5Fu"
   },
   "outputs": [],
   "source": [
    "# # Import PDF of some random resume\n",
    "# print(\"Select a resume to categorize:\")\n",
    "# upload = files.upload()\n",
    "# file_path = list(upload.keys())[0]\n",
    "# reader = PyPDF2.PdfReader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "adJQx-GGiHed"
   },
   "outputs": [],
   "source": [
    "# # nltk.download('stopwords')\n",
    "# # stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# def evaluate_pdf(reader):\n",
    "#   # Read resume text\n",
    "#   resume_text = ''\n",
    "#   for page in range(len(reader.pages)):\n",
    "#       text = reader.pages[page].extract_text()\n",
    "#       resume_text += text\n",
    "#   # print(\"Resume text (original):\\n\", resume_text)\n",
    "\n",
    "#   # Clean text (done in the same way as above in the Dataset section)\n",
    "#   resume_text = resume_text.lower()\n",
    "#   resume_text = re.sub(r'[^a-zA-z\\s]', '', resume_text)\n",
    "#   resume_text = re.sub(r'\\s', ' ', resume_text).strip()\n",
    "\n",
    "#   resume_text = ' '.join([word for word in resume_text.split() if word not in stop_words])\n",
    "#   # print(\"\\nResume text (cleaned):\\n\", resume_text)\n",
    "\n",
    "#   # Categorize resume using the model\n",
    "#   resume_text = tfidf.transform([resume_text]).toarray()\n",
    "#   prediction = model.predict(resume_text)\n",
    "#   predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))\n",
    "#   # print(f\"\\nImported Resume:\\n--Predicted = {predicted_label}\")\n",
    "#   return predicted_label[0]\n",
    "# evaluate_pdf(reader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbj4tBBwDkBI"
   },
   "source": [
    "## Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTxV9iFpWsQA"
   },
   "outputs": [],
   "source": [
    "    def evaluate_resume(resume_file_path):\n",
    "        resume_text = \"\"\n",
    "        with fitz.open(resume_file_path) as resume:\n",
    "            if resume.page_count == 0:\n",
    "                return \"PDF has no pages or could not be opened.\"\n",
    "\n",
    "            for page_num in range(resume.page_count):\n",
    "                page = resume[page_num]\n",
    "                resume_text += page.get_text(\"text\")  # Extract text from each page\n",
    "        resume_text = resume_text.lower()\n",
    "        resume_text = re.sub(r'[^a-zA-z\\s]', '', resume_text)\n",
    "        resume_text = re.sub(r'\\s', ' ', resume_text).strip()\n",
    "        resume_text = ' '.join([word for word in resume_text.split() if word not in stop_words])\n",
    "\n",
    "        # Categorize resume using the model\n",
    "        resume_text = tfidf.transform([resume_text]).toarray()\n",
    "        prediction = model.predict(resume_text)\n",
    "        predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))\n",
    "\n",
    "        # Send data to the Django backend\n",
    "        url = \"http://127.0.0.1:7860/save-input/\"  # Adjust based on your Django server URL\n",
    "        data = {'name': name}\n",
    "        try:\n",
    "        response = requests.post(url, json=data)\n",
    "        if response.status_code == 200:\n",
    "        return f\"Hello, {name}! (Saved to database)\"\n",
    "        else:\n",
    "        return f\"Error: {response.json().get('error', 'Unknown error')}\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "        return f\"Server error: {e}\"\n",
    "\n",
    "        return predicted_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "NG429NOqR2Vo",
    "outputId": "e12a4b0e-9207-4a97-9d02-4ef37c62b7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio\n",
    "demo = gradio.Interface(\n",
    "    fn=evaluate_resume,\n",
    "    inputs=[PDF(label=\"Document\")],\n",
    "    outputs= [gradio.Textbox(label=\"Classification Prediction\")],\n",
    "    title=\"Resume Classifier\"\n",
    ")\n",
    "demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "sGHwTUb4DbQ6"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
